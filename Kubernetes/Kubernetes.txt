	KUBERNETES

IN THE MASTER - 
	1) API SERVER - is the reception of the 
	2) ETCD - is the database of the kubernetes cluster 
	( ETCD contains all the data of the pods, users or ny data)
	3) CONTROLLER MANAGER - it is going to control the worker nodes 
	(checks if the worker node is running or not, what  is the capacity of the worker nodes, etc)
	4) SCHEDULER - creates the pods and the containers 
	
all of the 4 are going to run as containers on the master server

we can send messages to the kubernetes master through -  
1) UI - user interface
2) CLI - Kubectl (cli tool for kubernetes is kubectl)
3) API - Application programming interface

any of the commands through the above methods will reach the api server of the master first : 
Api server is like the reception area 

kubeadm - command to add node, manage node or anything with the node

kubeadm init (on master)

kubeadm join (on the worker)

Any instructions from the controller manager is going to connect to the worker nodes 
scheduler manager will connect to kubelet - hence agent based communication

STEPS : 

name all the nodes as master and worker nodes
(in real time we have the names as master.example.com - example would be the company name)


Docker configuration on master and worker nodes : 

 cat <<EOF | sudo tee /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
"max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF


sudo systemctl enable docker
sudo systemctl daemon-reload
sudo systemctl restart docker
sudo swapoff -a

sudo kubeadm init

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
cat ~/.kube/config (shows the info of config file)

Install Container Network Interface (CNI)
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml

Worker Nodes initialization - Worker1 & 2

sudo kubeadm token create --print-join-command
(Add sudo to the join command inside the worker nodes)

Verification:

kubectl get nodes (on the master node to see the nodes)

sudo kubeadm reset -f (resets the node) [do not do it unless necessary]

free -g (shows the memory in gb)
or 
free -m (shows the memory in mb)

sudo kubeadm init (initializes the master as administrator)

If you want to run the kubectl commands on the worker nodes then copy the admin.conf file to the worker 
nodes... copying the admin.conf file so that the kubectl can connect to the api server

sudo kubeadm token create --print-join-command


kubectl get nodes -o wide (shows extra columns of the node info in a list)

kubectl describe node <nodename> (shows detailed info about the nodes)

kubectl config view (shows the config file information with all the contexts)


CONTEXT IS THE ENVIRONMENT WE ARE IN (i.e., dev, staging or prod)

kubectl config (shows the modules) 

kubectl config current-context (shows the current context we are in)

kubectl config use-context <contextname> (switch to other contexts)

ex: kubectl config use-context kubernetes-admin@kubernetes

kubectl config get-contexts <contextname> 

kubectl cluster-info 

kubectl cluster-info dump > /tmp/cluster-dump (creates a cluster-dump folder with the cluster dump 
output)

if we have 4 diff app in our company what we will do is we create a namespace inside the vms 
where in each namespace a specific app container only is present

app1 namespace -- app1 containers only
app2 namespace -- app2 containers only

if we have 2 worker nodes -- we will logically create a namespace for each and every application
so if we have about 40 gb memory and we have 4 apps we will allocate the memory to each of the app
as much as the app requires 
if app1 need 15 gb -we allocate 15gb and app2 needs 5 gb we allocate 5gb and vice versa so that all 
the applications adjust in the worker nodes

HOW TO CREATE NAMESPACES
kubectl get pods -n <namespace-name> 
kubectl get all -n <namespace-name> 

kubectl get pods -n kube-system (shows the container pods with the specific namespaces kube-system) 
{add -o wide for more info}

-n is used to create namespaces

kubectl get pods -A (shows all the pods irrespective of namespaces)


REGISTERING WORKER NODES : 

to join the worker nodes to the cluster - 
1st method we did was using join command 
2nd method is - 

create a .json file

kubectl apply -f <filename> (to execute the file)

kubectl get nodes (to see the nodes)

to create a pod : 
kubectl run <podname> --image <imagename> --port <portnumber> (to create a pod)
kubectl run nginxpod --image

kubectl get pods (shows pods)
kubectl exec -it <podname> /bin/sh (to enter into the pod)
kubectl exec -it <podname> <linuxcommand> (to run any one command on the pod)

kubectl logs <podname> (shows logs)

KUBERNETES DASHBOARD : (UI)

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/... (creates kubernetes dashboard)
(to get this command search kubernetes dashboard in google and download the yaml file from there)

kubectl delete -f https://raw.githubusercontent.com/kubernetes/dashboard/... (deletes the kubernetes dashboard created)

kubernetes service means the loadbalancer 

kubectl edit svc -n <namespace-name> <namespace-name>
kubernetes get all -n kubernetes-dashboard 

open browser in the master node machine on the desktop 
htts://localhost:32012
token - 
kubectl -n <namespace> describe secret 
Devops engineers wont use UI -- we use it to show others to see the pods like agile scrum master,etc

BACKUP : 
the first thing as we see the database is to take a backup 
the main thing we do for a database is backup

how to take a backup for ETCD : 

etcdctl (suggestion to install etcdctl)
sudo snap install etcd
sudo apt install etcd-client

to take backup - we need to connect to etcd through username and password

Controller manager connects to the etcd through the pki file in /etc/kubernetes which contains all 
the certiicates
etcdctl snapshot save (you will get the whole command from the kubernetes.io website)

etcdctl snapshot status (shows the information of the backup snapshot which was taken)

restoring only works on a new etcd or if we have a brand new cluster... it wont work on the same 
cluster
Restore is only done when we have a multi master setup
etcd-backup.db (file in which the backup is stored)

UPGRADING KUBERNETES : 
kubeadm version
kubectl version
kubelet --version
kubectl get nodes
These all show the versions of kubernetes

kubeadm upgrade 

WORKLOADS : 

Main containers and side car containers - 
main - app, side car containers - security container or storage

we create a minimum of 1 and maximum of 5 containers per pod

Purpose or advantages of having multiple containers in a pod - 
- latency is reduced between containers 
- storage can be common for all the containers - 
(same shared volume to have the same shared volume so that app and logs container can use the same shared volume)
- IP address can be shared for all the containers - 
(they have the same ip address as pods have the ip address) 

the 3 major components of a VM or container
Compute - Cpu and memory 
network - 
storage - 

the sizes of the containers will vary inside a pod - example : app container will have more size than 
other containers
Note - kubernetes manages only pods and not containers
we cannot also add or delete containers to a running pod

HOW TO CREATE A MANIFESTS FILE : 

Manifests file contains : 
apiVersion: v1
kind: Pod
metadata:
  name: imagename
spec: 
  containers: 
    - name: 
kubectl api-resources ()

kubectl explain pod (shows the api version, kind, metadata, specs - how to create a manifests file)
kubectl explain pod.apiVersion (shows to create manifests file apiVersion)
kubectl explain pod.spec.containers (shows containers)
kubectl explain pod.spec.containers (shows mages)
kubectl explain pod.spec.containers --recursive 
(shows everything related to creating the manifests file)

cat pod.yaml (is the manifests file)

kubectl apply -f <filename> (to create pod from manifests file)
Note : pod status will be running only if the contaienrs are in a running state
podname and container name can be different 

INIT-CONTAINER : 

init container will start first and if the init container is successful only then the main container 
will start 

kubectl get pods <podname> -w (-w is watch state, the output keeps changing when a new event in 
the command occurs)

RESOURCE LIMITS : 

Assigning limits to a container - like cpu ram, memory, etc

STATIC PODS :

static pod - when a pod is run only on one node. K8s admin chooses which worker node to run the pod
creating a pod from the worker node through kubelet
USECASE : we can monitor the traffic or any suspicious activity by creating a pod on the worker node 
and it cannot be controlled by master node if we want 

ADDING A .yaml manifests file inside the /etc/kubernetes/manifests creates a static pod inside the 
node
How to identify static pod from normal pod? - static pod will have the node-name attached to the 
podname
so any pod with the nodename attached to it is a static pod

PET VS CATTLE : 
the way we manage pet is different than how we manage cattle
return from cattle is much more than pet
pod = pet , deployment= cattle

Deployment will delete the existing pods and create new pods

kubectl get deploy (shows all deployments)

kubectl explain deploy (explains how to write manifests deployment file)
kubectl explain deploy.spec
kubectl explain deploy.spec.template.spec

kubectl get pods
kubectl get replicaset 

kubectl get deploy (shows the deployment)
deployment - is simillar to service in docker... it contains replica pods with same containers, only 
the name is different

ADVANTAGE OF DEPLOYMENT: 
1) we can create same multiple pods
2) whenever there is an update, we can apply it through deployments
3) scaling the number of pods - increase or decrease

kubectl rollout history deploy <deploymentname> (shows all the history of the deployment)
(Revision is same as commit in git)

UPDATING: 

kubectl set image deployment/<deploymentname> <containername=imagename> (updates the present image)
kubectl rollout history deploy <deploymentname> (now it shows the second revision... it indicates it has updated)
kubectl rollout history deploy <deploymentname> --revision=<no.of.your-revision> (describes the revision)
kubectl get pods (new pods and containers are created with the updated image)
kubectl get replicaset (shows the different replicasets)
kubectl get rs (shows the different replicasets)
for each and every revision a replicaset will be created (revision is same as commit in git)
rolling update - in case of update kubernetes will create one pod and test it if it running good and 
then it will delete the previous pods and create new pods
CANARY DEPLOYMENT(in devops) - same as - ROLLING UPDATE(in kubernetes)
rolling update - in case of an update if one pod is successfully created then the previous pod will 
be deleted and then other pod is created another pod from the deployment is deleted and so on

kubectl set image deployment/<deploymentname> <containername=imagename> --record (record will set a 
change cause or message as to why the revisison had been done- simillar to commit message in git)

Check the change cause by : kubectl rollout history deploy <deploymentname> 

ROLLBACK: 

kubectl rollout undo (deployment goes to previous version of the image)

kubectl rollout undo deploy <deployment-name> (rollback to the previous version)
kubectl get pods | grep deploy 

kubectl rollout undo deploy <deployment-name> --to-revision=<no.of-revision-u-want-to-rollout-to>
(to go back to any revision number you want)
kubectl rollout undo deploy nginx-deployment --to-revision=1 (to rollback to revision 1)

MANUAL SCALING: 

scale up and scale down 
kubectl scale --help (shows all the modules)
kubectl scale deployment <deploymentname> --replicas=<no.ofreplicasuwant>
kubectl get rs or kubectl get replicaset (shows the replicasets)
kubectl get deploy (shows the deployments, depending on the number of rs u can scale up and down)

when to use replica mode and glocal mode: 
replica mode is to scale up and down, glocal mode cannot be scaled
global mode is only used when we need only one container in all the nodes

DAEMON SETS: 
there will be one pod which will be running on all the nodes 
Realtime use case: fluentd
Fluentd - it will collect the logs from any application and will store them in a central space

kubectl get daemonset or kubectl get ds -A (shows all daemon sets) 
(added -A for all namespaces) 

daemonset.yaml

kubectl apply -f daemonset.yaml

kubectl get ds -n kube-system 
kubectl get pods -n kube-system -o wide | grep fluent

JOBS AND CRONJOBS: 

updating the database : 
the app cam be updated by set image but how to update database? 
adding the tables and then upadting the deployment: 
On the existing database pods we need to add tables 

A migration job pod is created (simillar to init container) and when it is successful a new pod with 
version 2 is created 

Tool to update : ArgoCD 

ArgoCD: 
step -1 : add 8 new tables [job]
step-2 uber 1.5 [update deployment]

Job pod: 
a given job is done by the created pod and it remains without using any further resources 
suppose the job is to print date or message it creates a pod and prints the message and remains
k logs <podname> 
crontab - for scheduling the job
***** 
1st* - minute 
2nd* - hour 
3rd* - day of the month 
4th* - month 
5th* - day of the week

kubectl apply -f cronjob
kubectl get cronjob
kubectlget jobs
kubectlget jobs -w ( -w to see the execution status of the command)
New jobs/jobpods get created everytime based on the schedule set in the cronjobs

NAMESPACE:  

kubectl get namespace or kubectl get ns
example: if i have 5 worker nodes and i have diff apps to deployed on the worker nodes, i have to 
provide a capacity for all of them to run 
to group resources we have to craete namespaces
kubectl create ns insta
kubectl create ns meta 
kubectl create ns whatsapp

USES OF NAMESPACES: 
1) same resources under 1 namespace - so when we create a deployment we create them inside the 
namespaces
2) set quota to restrict the resources 
3) set roles or access restrictions - users under the namespace can only modify or view the resources 
under their namespaces 

kubectl apply -f <deployment-filename> -n <namepsacename> ()
ex: kubectl apply -f deploy -n insta 

kubectl get all -n <namepsacename> (shows all the resources under the namespace)
kubectl delete ns <namespacename> (deletes the namespace)

































































NOTES : 

devops people usually use the aws cli

when we send a message through kubectl it is received by the Api server - Api server will send message 
to scheduler - scheduler to control manager and etcd which will give the deatils of the availability 
of the worker nodes and then the container is created depending on the availability

Master which has 8gb ram /4vCPU's
it can handle 25 worker nodes of 8gb ram /4vCPU's

EXPLANATION OF KUBEADM INIT COMMAND : 

remote version is much newer falling back to stable version- 

Preflight - kubeadm will check if the node is good enough to work as master and then it will start 
downloading the containers such as API, CM, Scheduler as they run as containers

docker images command shows the apiserver, manaer and other images 

Certs - generates the certificates for the interconnectivity of api with cm and scheduler 
(simillar to password login)

Kubeconfig - configuration of the 

sudo ls /etc/kubernetes/ (check the contents of this folder)

kubelet - is the agent

control plane - 
sudo ls /etc/kubernetes/manifest/ (contains all the specs)

Container networking interface - 90 percent of people are using calico in the realtime, so right now 
we are using calico

Component which creates the containers on the worker nodes - scheduler


ENVIRONMENT - Developer, staging , production
App will be deployed in developing environment first then to the staging environment and then to the 
production

Development --> staging --> production

In kubernetes - Kubernetes --> Development (master and worker 1&2)--> staging (master and worker -1-4)
--> production (master and worker -1-10)
(it means we have 3 different clusters in all the environments combined)

cluster means -- master and worker together is called as a cluster

Akshay (DevOps) (CKA)

if we want to do get nodes : we have to go into each of the environment master and do get nodes
connect to dev -- kubectl get nodes
connect to prod --  kubectl get nodes
how to switch between environment clusters and connect to all the master nodes from one to other? 

MANIFESTS FILE :

TO SET ALIAS FOR ANY COMMAND : alias k=kubectl 
ex : k get pods is same as typing kubectl get pods

ADDING A .yaml manifests file inside the /etc/kubernetes/manifests creates a static pod inside the 
node

api server, controller scheduler and etcd all run on the kube-system namespace and also the daemon sets

KUBERNETES DOCUMENT: 

kubernetes.io/docs/home

ALIAS: 

alias k=kubectl
file for alias: 
vi .bashrc (in the root directory in the .bashrc file you can set the alias by adding the lines in the 
file and then type command <source .bashrc> and the alias is ready to use)

















TASKS : 

Learn about namespaces and cgroups

KUBERNETES IS VERY IMPORTANT : get deep into it

HELM : Real time indsutry usage... mostly what we do in the industry


Control Plane

container  - has three components -  compute, network, storage

AWS CLI - know about this
terraform is - API - Application programming interface -  Know about this

Heartbeat timestamp - worker nodes sends a message to the controller manager 

see chef, puppet, dynatrace

CRI - 

https://kubernetes.io/releases/

sudo ls /etc/kubernetes/
cat admin.conf (to see the config file)

SCP - scp labsuser@ipaddress/filepath /etc/kubernetes/admin.conf

Key Value store - KVS database

know what this error is 
W: An error occurred during the signature verification. The repository is not updated and the previous 
index files will be used. GPG error: https://packages.cloud.google.com/apt kubernetes-xenial 
InRelease: The following signatures couldn't be verified because the public key is not available: 
NO_PUBKEY B53DC80D13EDEF05

sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

LATENCY FOR THE CONTAINERS

DATATYPE : string list integer dictionary float (know about all these)

APPLICATION CONFIGURATION - READ ABOUT IT








DOUBTS : 

Hi Swami, along with this trainings, what will you suggest additionally to grab good hold on K8s?

CKA


as a manager every 6 months you will be doing upgrades


installation process in real time for both master and worker nodes

so every worker node has to have same CRI or they can have different? 
ans - best practice is to have the same CRI on all the worker nodes

ERROR SOLVING : 
nodes and master not ready : 
sudo service kubelet status
sudo service kubelet restart

YAML 
Good example - https://editor.swagger.io/
Video learning - Yaml Tutorial | Learn YAML in 18 mins
Cheat sheet - https://learnxinyminutes.com/docs/yaml/

https://kubernetes.io/releases/